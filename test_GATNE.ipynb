{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de83a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from numpy import random\n",
    "from torch.nn.parameter import Parameter\n",
    "from OpenAttMultiGL.utils.dataset import dataset\n",
    "from OpenAttMultiGL.utils.process import * \n",
    "from OpenAttMultiGL.model.GATNE.utils import *\n",
    "#from mGCN_Toolbox.model.GATNE.walk import *\n",
    "from OpenAttMultiGL.model.X_GOAL.evaluate import *\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--input', type=str, default='Amazon',\n",
    "                        help='Input dataset path')\n",
    "    \n",
    "    parser.add_argument('--features', type=str, default=None,\n",
    "                        help='Input node features')\n",
    "\n",
    "    parser.add_argument('--walk-file', type=str, default=None,\n",
    "                        help='Input random walks')\n",
    "\n",
    "    parser.add_argument('--epoch', type=int, default=10,\n",
    "                        help='Number of epoch. Default is 100.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='Number of batch_size. Default is 64.')\n",
    "\n",
    "    parser.add_argument('--eval-type', type=str, default='all',\n",
    "                        help='The edge type(s) for evaluation.')\n",
    "    \n",
    "    parser.add_argument('--schema', type=str, default=None,\n",
    "                        help='The metapath schema (e.g., U-I-U,I-U-I).')\n",
    "\n",
    "    parser.add_argument('--dimensions', type=int, default=200,\n",
    "                        help='Number of dimensions. Default is 200.')\n",
    "\n",
    "    parser.add_argument('--edge-dim', type=int, default=10,\n",
    "                        help='Number of edge embedding dimensions. Default is 10.')\n",
    "    \n",
    "    parser.add_argument('--att-dim', type=int, default=20,\n",
    "                        help='Number of attention dimensions. Default is 20.')\n",
    "\n",
    "    parser.add_argument('--walk-length', type=int, default=10,\n",
    "                        help='Length of walk per source. Default is 10.')\n",
    "\n",
    "    parser.add_argument('--num-walks', type=int, default=20,\n",
    "                        help='Number of walks per source. Default is 20.')\n",
    "\n",
    "    parser.add_argument('--window-size', type=int, default=5,\n",
    "                        help='Context size for optimization. Default is 5.')\n",
    "    \n",
    "    parser.add_argument('--negative-samples', type=int, default=5,\n",
    "                        help='Negative samples for optimization. Default is 5.')\n",
    "    \n",
    "    parser.add_argument('--neighbor-samples', type=int, default=10,\n",
    "                        help='Neighbor samples for aggregation. Default is 10.')\n",
    "\n",
    "    parser.add_argument('--patience', type=int, default=5,\n",
    "                        help='Early stopping patience. Default is 5.')\n",
    "    \n",
    "    parser.add_argument('--num-workers', type=int, default=16,\n",
    "                        help='Number of workers for generating random walks. Default is 16.')\n",
    "    \n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def get_batches(pairs, neighbors, batch_size):\n",
    "    n_batches = (len(pairs) + (batch_size - 1)) // batch_size\n",
    "\n",
    "    for idx in range(n_batches):\n",
    "        x, y, t, neigh = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            index = idx * batch_size + i\n",
    "            if index >= len(pairs):\n",
    "                break\n",
    "            x.append(pairs[index][0])\n",
    "            y.append(pairs[index][1])\n",
    "            t.append(pairs[index][2])\n",
    "            neigh.append(neighbors[pairs[index][0]])\n",
    "        yield torch.tensor(x), torch.tensor(y), torch.tensor(t), torch.tensor(neigh)\n",
    "\n",
    "\n",
    "class GATNEModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
    "    ):\n",
    "        super(GATNEModel, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding_u_size = embedding_u_size\n",
    "        self.edge_type_count = edge_type_count\n",
    "        self.dim_a = dim_a\n",
    "\n",
    "        self.features = None\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "            feature_dim = self.features.shape[-1]\n",
    "            self.embed_trans = Parameter(torch.FloatTensor(feature_dim, embedding_size))\n",
    "            self.u_embed_trans = Parameter(torch.FloatTensor(edge_type_count, feature_dim, embedding_u_size))\n",
    "        else:\n",
    "            self.node_embeddings = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
    "            self.node_type_embeddings = Parameter(\n",
    "                torch.FloatTensor(num_nodes, edge_type_count, embedding_u_size)\n",
    "            )\n",
    "        self.trans_weights = Parameter(\n",
    "            torch.FloatTensor(edge_type_count, embedding_u_size, embedding_size)\n",
    "        )\n",
    "        self.trans_weights_s1 = Parameter(\n",
    "            torch.FloatTensor(edge_type_count, embedding_u_size, dim_a)\n",
    "        )\n",
    "        self.trans_weights_s2 = Parameter(torch.FloatTensor(edge_type_count, dim_a, 1))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.features is not None:\n",
    "            self.embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "            self.u_embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        else:\n",
    "            self.node_embeddings.data.uniform_(-1.0, 1.0)\n",
    "            self.node_type_embeddings.data.uniform_(-1.0, 1.0)\n",
    "        self.trans_weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        self.trans_weights_s1.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        self.trans_weights_s2.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "\n",
    "    def forward(self, train_inputs, train_types, node_neigh):\n",
    "        if self.features is None:\n",
    "            node_embed = self.node_embeddings[train_inputs]\n",
    "            node_embed_neighbors = self.node_type_embeddings[node_neigh]\n",
    "        else:\n",
    "            node_embed = torch.mm(self.features[train_inputs], self.embed_trans)\n",
    "            node_embed_neighbors = torch.einsum('bijk,akm->bijam', self.features[node_neigh], self.u_embed_trans)\n",
    "        node_embed_tmp = torch.diagonal(node_embed_neighbors, dim1=1, dim2=3).permute(0, 3, 1, 2)\n",
    "        node_type_embed = torch.sum(node_embed_tmp, dim=2)\n",
    "\n",
    "        trans_w = self.trans_weights[train_types]\n",
    "        trans_w_s1 = self.trans_weights_s1[train_types]\n",
    "        trans_w_s2 = self.trans_weights_s2[train_types]\n",
    "\n",
    "        attention = F.softmax(\n",
    "            torch.matmul(\n",
    "                torch.tanh(torch.matmul(node_type_embed, trans_w_s1)), trans_w_s2\n",
    "            ).squeeze(2),\n",
    "            dim=1,\n",
    "        ).unsqueeze(1)\n",
    "        node_type_embed = torch.matmul(attention, node_type_embed)\n",
    "        node_embed = node_embed + torch.matmul(node_type_embed, trans_w).squeeze(1)\n",
    "\n",
    "        last_node_embed = F.normalize(node_embed, dim=1)\n",
    "\n",
    "        return last_node_embed\n",
    "\n",
    "\n",
    "class NSLoss(nn.Module):\n",
    "    def __init__(self, num_nodes, num_sampled, embedding_size):\n",
    "        super(NSLoss, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_sampled = num_sampled\n",
    "        self.embedding_size = embedding_size\n",
    "        self.weights = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
    "        self.sample_weights = F.normalize(\n",
    "            torch.Tensor(\n",
    "                [\n",
    "                    (math.log(k + 2) - math.log(k + 1)) / math.log(num_nodes + 1)\n",
    "                    for k in range(num_nodes)\n",
    "                ]\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "\n",
    "    def forward(self, input, embs, label):\n",
    "        n = input.shape[0]\n",
    "        log_target = torch.log(\n",
    "            torch.sigmoid(torch.sum(torch.mul(embs, self.weights[label]), 1))\n",
    "        )\n",
    "        negs = torch.multinomial(\n",
    "            self.sample_weights, self.num_sampled * n, replacement=True\n",
    "        ).view(n, self.num_sampled)\n",
    "        noise = torch.neg(self.weights[negs])\n",
    "        sum_log_sampled = torch.sum(\n",
    "            torch.log(torch.sigmoid(torch.bmm(noise, embs.unsqueeze(2)))), 1\n",
    "        ).squeeze()\n",
    "\n",
    "        loss = log_target + sum_log_sampled\n",
    "        return -loss.sum() / n\n",
    "\n",
    "\n",
    "def train_model(network_data, feature_dic):\n",
    "    vocab, index2word, train_pairs = generate(network_data, args.num_walks, args.walk_length, args.schema, file_name, args.window_size, args.num_workers, args.walk_file)\n",
    "\n",
    "    edge_types = list(network_data.keys())\n",
    "\n",
    "    num_nodes = len(index2word)\n",
    "    edge_type_count = len(edge_types)\n",
    "    epochs = args.epoch\n",
    "    batch_size = args.batch_size\n",
    "    embedding_size = args.dimensions\n",
    "    embedding_u_size = args.edge_dim\n",
    "    u_num = edge_type_count\n",
    "    num_sampled = args.negative_samples\n",
    "    dim_a = args.att_dim\n",
    "    att_head = 1\n",
    "    neighbor_samples = args.neighbor_samples\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    neighbors = generate_neighbors(network_data, vocab, num_nodes, edge_types, neighbor_samples)\n",
    "\n",
    "    features = None\n",
    "    if feature_dic is not None:\n",
    "        feature_dim = len(list(feature_dic.values())[0])\n",
    "        print('feature dimension: ' + str(feature_dim))\n",
    "        features = np.zeros((num_nodes, feature_dim), dtype=np.float32)\n",
    "        for key, value in feature_dic.items():\n",
    "            if key in vocab:\n",
    "                features[vocab[key].index, :] = np.array(value)\n",
    "        features = torch.FloatTensor(features).to(device)\n",
    "\n",
    "    model = GATNEModel(\n",
    "        num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
    "    )\n",
    "    nsloss = NSLoss(num_nodes, num_sampled, embedding_size)\n",
    "\n",
    "    model.to(device)\n",
    "    nsloss.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [{\"params\": model.parameters()}, {\"params\": nsloss.parameters()}], lr=1e-4\n",
    "    )\n",
    "    \n",
    "    best_score = 0\n",
    "    test_score = (0.0, 0.0, 0.0)\n",
    "    patience = 0\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(train_pairs)\n",
    "        batches = get_batches(train_pairs, neighbors, batch_size)\n",
    "        print(batches.shape)\n",
    "       #batches = get_batches(train_pairs, neighbors, batch_size)\n",
    "        \n",
    "        embes = model.node_embeddings#[t.test_id]\n",
    "        #print(embes.shape)\n",
    "        #print(t.dataset)\n",
    "        data_iter = tqdm(\n",
    "            batches,\n",
    "            desc=\"epoch %d\" % (epoch),\n",
    "            bar_format=\"{l_bar}{r_bar}\",\n",
    "        )\n",
    "        batch = torch.tensor(args.batch_size)\n",
    "        avg_loss = 0.0\n",
    "        l = []\n",
    "        l.append(args.batch_size)\n",
    "        l.append(2)\n",
    "        l.append(args.neighbor_samples)\n",
    "        #args.neighbor_samples\n",
    "        node_neigh = torch.tensor(l)\n",
    "        print(l)\n",
    "        for i, data in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            #loss = criterion(model[t.train_id], t.labels[t.train_id])\n",
    "            embs = model(data[0].to(device), data[2].to(device), data[3].to(device),)\n",
    "            #print(data[0].to(device).shape)\n",
    "            #print(data[2].to(device).shape)\n",
    "            #print(data[3].to(device).shape)\n",
    "            \n",
    "            #print(data[1].to(device).shape)\n",
    "            loss = nsloss(data[0].to(device), embs, data[1].to(device))\n",
    "            #loss = nsloss(batch, embs, batch)\n",
    "            #print(loss.shape)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "           # avg_loss += loss.item()\n",
    "\n",
    "            #if i % 5000 == 0:\n",
    "               # post_fix = {\n",
    "              #      \"epoch\": epoch,\n",
    "              #      \"iter\": i,\n",
    "              #      \"avg_loss\": avg_loss / (i + 1),\n",
    "              #      \"loss\": loss.item(),\n",
    "              #  }\n",
    "              #  data_iter.write(str(post_fix))\n",
    "\n",
    "        #final_model = dict(zip(edge_types, [dict() for _ in range(edge_type_count)]))\n",
    "        #for i in range(num_nodes):\n",
    "            #train_inputs = torch.tensor([i for _ in range(edge_type_count)]).to(device)\n",
    "            #train_types = torch.tensor(list(range(edge_type_count))).to(device)\n",
    "            #node_neigh = torch.tensor(\n",
    "                #[neighbors[i] for _ in range(edge_type_count)]\n",
    "            #).to(device)\n",
    "            #node_emb = model(train_inputs, train_types, node_neigh)\n",
    "            #for j in range(edge_type_count):\n",
    "                #final_model[edge_types[j]][index2word[i]] = (\n",
    "                    #node_emb[j].cpu().detach().numpy()\n",
    "                #)\n",
    "\n",
    "        #valid_aucs, valid_f1s, valid_prs = [], [], []\n",
    "        #test_aucs, test_f1s, test_prs = [], [], []\n",
    "        for i in range(edge_type_count):\n",
    "            if args.eval_type == \"all\" or edge_types[i] in args.eval_type.split(\",\"):\n",
    "                macro,micro = evaluate_GATNE(\n",
    "                    final_model[edge_types[i]],\n",
    "                    t.testing_true_data_by_edge[edge_types[i]],\n",
    "                    t.testing_false_data_by_edge[edge_types[i]],\n",
    "                    t.num_classes\n",
    "                )\n",
    "                #test_aucs.append(tmp_auc)\n",
    "                #test_f1s.append(tmp_f1)\n",
    "                #test_prs.append(tmp_pr)\n",
    "                \n",
    "                \n",
    "        test_embs = model.node_embeddings#[t.test_id]  \n",
    "        test_lbls = torch.argmax(t.labels[t.test_id], dim=1)\n",
    "        nmi = run_kmeans(test_embs, test_lbls, t.num_classes)\n",
    "        sim = run_similarity_search(test_embs, test_lbls)\n",
    "        print(\"Epoch: \", epoch)\n",
    "        print(\"Macro_F1:\", macro)\n",
    "        print(\"Micro_F1:\", micro)\n",
    "        print(\"NMI:\", nmi)\n",
    "        print(\"SIM:\", sim)\n",
    "\n",
    "        #average_auc = np.mean(test_aucs)\n",
    "        #average_f1 = np.mean(test_f1s)\n",
    "        #average_pr = np.mean(test_prs)\n",
    "\n",
    "        #cur_score = np.mean(valid_aucs)\n",
    "        #if cur_score > best_score:\n",
    "           # best_score = cur_score\n",
    "          #  test_score = (average_auc, average_f1, average_pr)\n",
    "           # patience = 0\n",
    "        #else:\n",
    "            #patience += 1\n",
    "            #if patience > args.patience:\n",
    "                #print(\"Early Stopping\")\n",
    "                #break\n",
    "    #pred = model.max(1).indices\n",
    "    #macro,micro,nmi,sim = evaluate(embs,t.train_id,t.valid_id,t.test_id,t.gcn_labels)\n",
    "    #nmi = run_kmeans(t.labels,pred, nb_classes)\n",
    "    #sim = run_similarity_search(t.labels,pred)\n",
    "    return macro,micro,nmi,sim\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    file_name = args.input\n",
    "    print(args.lr)\n",
    "    if args.features is not None:\n",
    "        feature_dic = load_txt_feature_data(args.features)\n",
    "    else:\n",
    "        feature_dic = None\n",
    "    t = dataset(file_name)\n",
    "    #training_data_by_type = load_training_data(\"mGCN_Toolbox/data/GATNE/\"+file_name + \"/train.txt\")\n",
    "    #valid_true_data_by_edge, valid_false_data_by_edge = load_valid_data(\n",
    "        #\"mGCN_Toolbox/data/GATNE/\" +file_name + \"/valid.txt\"\n",
    "    #)\n",
    "    #testing_true_data_by_edge, testing_false_data_by_edge = load_testing_data(\n",
    "        #\"mGCN_Toolbox/data/GATNE/\"+ file_name + \"/test.txt\"\n",
    "    #)\n",
    "    #print(t.dataset[0])\n",
    "\n",
    "    #macro,micro,nmi,sim = train_model(t.training_data_by_type, feature_dic)\n",
    "    macro,micro,nmi,sim = train_model(t.training_data_by_type, feature_dic)\n",
    "\n",
    "    #print(\"Macro_F1:\", macro)\n",
    "    #print(\"Micro_F1:\", micro)\n",
    "    #print(\"NMI: \", nmi)\n",
    "    #print(\"SIM: \", sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884699a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import random\n",
    "\n",
    "node_embeddings = Parameter(torch.FloatTensor(50, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f749176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 200])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b87837b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbar_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{l_bar}\u001b[39;49;00m\u001b[38;5;132;43;01m{r_bar}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "data_iter = tqdm(\n",
    "            500,\n",
    "            desc=\"epoch %d\" % (500),\n",
    "            bar_format=\"{l_bar}{r_bar}\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b3c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
