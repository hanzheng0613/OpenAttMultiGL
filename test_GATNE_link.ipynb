{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d334ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Best auc: 0.540824921648016\n",
      "Best ap: 0.5571599006652832\n",
      "Epoch: 2\n",
      "Best auc: 0.5409480064088654\n",
      "Best ap: 0.5584388971328735\n",
      "Epoch: 3\n",
      "Best auc: 0.5425082191798647\n",
      "Best ap: 0.5569455623626709\n",
      "Epoch: 6\n",
      "Best auc: 0.5426453276712655\n",
      "Best ap: 0.557116687297821\n",
      "Epoch: 8\n",
      "Best auc: 0.5430392051512587\n",
      "Best ap: 0.5624074935913086\n",
      "Epoch: 10\n",
      "Best auc: 0.5431353425802055\n",
      "Best ap: 0.5602940320968628\n",
      "Epoch: 11\n",
      "Best auc: 0.5434242205174901\n",
      "Best ap: 0.5579119920730591\n",
      "Epoch: 12\n",
      "Best auc: 0.5465774066442852\n",
      "Best ap: 0.5616952776908875\n",
      "Epoch: 35\n",
      "Best auc: 0.547552147880995\n",
      "Best ap: 0.5638231635093689\n",
      "Epoch: 201\n",
      "Best auc: 0.5477372969488172\n",
      "Best ap: 0.56381756067276\n",
      "Epoch: 330\n",
      "Best auc: 0.5493442789366977\n",
      "Best ap: 0.5650149583816528\n",
      "Average-percision: 0.5574102616906166 0.0024197407410224384\n",
      "Average-AUC: 0.5414257875551112 0.0024546388996624104\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from numpy import random\n",
    "from torch.nn.parameter import Parameter\n",
    "from OpenAttMultiGL.utils.dataset import dataset\n",
    "from OpenAttMultiGL.utils.process import * \n",
    "from OpenAttMultiGL.model.GATNE.utils import *\n",
    "#from mGCN_Toolbox.model.GATNE.walk import *\n",
    "from OpenAttMultiGL.model.GATNE.embedder_link import *\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import random\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "def get_batches(pairs, neighbors, batch_size):\n",
    "    n_batches = (len(pairs) + (batch_size - 1)) // batch_size\n",
    "\n",
    "    for idx in range(n_batches):\n",
    "        x, y, t, neigh = [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            index = idx * batch_size + i\n",
    "            if index >= len(pairs):\n",
    "                break\n",
    "            x.append(pairs[index][0])\n",
    "            y.append(pairs[index][1])\n",
    "            t.append(pairs[index][2])\n",
    "            neigh.append(neighbors[pairs[index][0]])\n",
    "        yield torch.tensor(x), torch.tensor(y), torch.tensor(t), torch.tensor(neigh)\n",
    "\n",
    "\n",
    "class GATNEModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
    "    ):\n",
    "        super(GATNEModel, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding_u_size = embedding_u_size\n",
    "        self.edge_type_count = edge_type_count\n",
    "        self.dim_a = dim_a\n",
    "\n",
    "        self.features = None\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "            feature_dim = self.features.shape[-1]\n",
    "            self.embed_trans = Parameter(torch.FloatTensor(feature_dim, embedding_size))\n",
    "            self.u_embed_trans = Parameter(torch.FloatTensor(edge_type_count, feature_dim, embedding_u_size))\n",
    "        else:\n",
    "            self.node_embeddings = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
    "            self.node_type_embeddings = Parameter(\n",
    "                torch.FloatTensor(num_nodes, edge_type_count, embedding_u_size)\n",
    "            )\n",
    "        self.trans_weights = Parameter(\n",
    "            torch.FloatTensor(edge_type_count, embedding_u_size, embedding_size)\n",
    "        )\n",
    "        self.trans_weights_s1 = Parameter(\n",
    "            torch.FloatTensor(edge_type_count, embedding_u_size, dim_a)\n",
    "        )\n",
    "        self.trans_weights_s2 = Parameter(torch.FloatTensor(edge_type_count, dim_a, 1))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.features is not None:\n",
    "            self.embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "            self.u_embed_trans.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        else:\n",
    "            self.node_embeddings.data.uniform_(-1.0, 1.0)\n",
    "            self.node_type_embeddings.data.uniform_(-1.0, 1.0)\n",
    "        self.trans_weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        self.trans_weights_s1.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "        self.trans_weights_s2.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "\n",
    "    def forward(self, train_inputs, train_types, node_neigh):\n",
    "        if self.features is None:\n",
    "            node_embed = self.node_embeddings[train_inputs]\n",
    "            node_embed_neighbors = self.node_type_embeddings[node_neigh]\n",
    "        else:\n",
    "            node_embed = torch.mm(self.features[train_inputs], self.embed_trans)\n",
    "            node_embed_neighbors = torch.einsum('bijk,akm->bijam', self.features[node_neigh], self.u_embed_trans)\n",
    "        node_embed_tmp = torch.diagonal(node_embed_neighbors, dim1=1, dim2=3).permute(0, 3, 1, 2)\n",
    "        node_type_embed = torch.sum(node_embed_tmp, dim=2)\n",
    "\n",
    "        trans_w = self.trans_weights[train_types]\n",
    "        trans_w_s1 = self.trans_weights_s1[train_types]\n",
    "        trans_w_s2 = self.trans_weights_s2[train_types]\n",
    "\n",
    "        attention = F.softmax(\n",
    "            torch.matmul(\n",
    "                torch.tanh(torch.matmul(node_type_embed, trans_w_s1)), trans_w_s2\n",
    "            ).squeeze(2),\n",
    "            dim=1,\n",
    "        ).unsqueeze(1)\n",
    "        node_type_embed = torch.matmul(attention, node_type_embed)\n",
    "        node_embed = node_embed + torch.matmul(node_type_embed, trans_w).squeeze(1)\n",
    "\n",
    "        last_node_embed = F.normalize(node_embed, dim=1)\n",
    "\n",
    "        return last_node_embed\n",
    "\n",
    "\n",
    "class NSLoss(nn.Module):\n",
    "    def __init__(self, num_nodes, num_sampled, embedding_size):\n",
    "        super(NSLoss, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_sampled = num_sampled\n",
    "        self.embedding_size = embedding_size\n",
    "        self.weights = Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
    "        self.sample_weights = F.normalize(\n",
    "            torch.Tensor(\n",
    "                [\n",
    "                    (math.log(k + 2) - math.log(k + 1)) / math.log(num_nodes + 1)\n",
    "                    for k in range(num_nodes)\n",
    "                ]\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
    "\n",
    "    def forward(self, input, embs, label):\n",
    "        n = input.shape[0]\n",
    "        log_target = torch.log(\n",
    "            torch.sigmoid(torch.sum(torch.mul(embs, self.weights[label]), 1))\n",
    "        )\n",
    "        negs = torch.multinomial(\n",
    "            self.sample_weights, self.num_sampled * n, replacement=True\n",
    "        ).view(n, self.num_sampled)\n",
    "        noise = torch.neg(self.weights[negs])\n",
    "        sum_log_sampled = torch.sum(\n",
    "            torch.log(torch.sigmoid(torch.bmm(noise, embs.unsqueeze(2)))), 1\n",
    "        ).squeeze()\n",
    "\n",
    "        loss = log_target + sum_log_sampled\n",
    "        return -loss.sum() / n\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    file_name = args.input\n",
    "    #print(args)\n",
    "    if args.features is not None:\n",
    "        feature_dic = load_feature_data(args.features)\n",
    "    else:\n",
    "        feature_dic = None\n",
    "    \n",
    "    s = dataset('dblp')\n",
    "    num_nodes = s.sequence_adj[0].shape[0]\n",
    "    #print('node:', s.sequence_adj[0].shape[0])\n",
    "    \n",
    "    edge_type_count = len(s.sequence_adj)\n",
    "    batch_size = args.batch_size\n",
    "    embedding_size = args.dimensions\n",
    "    embedding_u_size = args.edge_dim\n",
    "    \n",
    "    dim_a = args.att_dim\n",
    "    features = None\n",
    "    \n",
    "    num_sampled = args.negative_samples\n",
    "    model = GATNEModel(\n",
    "        num_nodes, embedding_size, embedding_u_size, edge_type_count, dim_a, features\n",
    "    )\n",
    "    nsloss = NSLoss(num_nodes, num_sampled, embedding_size)\n",
    "    #print(type(model.node_embeddings))\n",
    "    #model.to(device)\n",
    "    #nsloss.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [{\"params\": model.parameters()}, {\"params\": nsloss.parameters()}], lr=1e-4\n",
    "    )\n",
    "    \n",
    "    num_classes = s.gcn_labels.shape[1]\n",
    "    split_edges = mask_test_edges(s.features, s.edge_list[0],1)\n",
    "    \n",
    "    split_edges['train']['label'] = torch.cat(\n",
    "        (split_edges['train']['label_pos'], split_edges['train']['label_neg']))#.to(args.device)\n",
    "    split_edges['valid']['label'] = torch.cat(\n",
    "        (split_edges['valid']['label_pos'], split_edges['valid']['label_neg']))#.to(args.device)\n",
    "    split_edges['test']['label'] = torch.cat(\n",
    "        (split_edges['test']['label_pos'], split_edges['test']['label_neg']))#.to(args.device)\n",
    "    s_edge = split_edges\n",
    "    #split_edge = mask_test_edges(t.HAN_features, split_edges, 1, 0.1, 0.5)\n",
    "    #model.node_embeddings.detach().numpy()\n",
    "    AUC, ap, hits = link_evaluate(model.node_embeddings.detach().numpy(),s_edge,num_classes)\n",
    "    print(\"Average-precision:\", np.mean(ap), np.std(ap))\n",
    "    print(\"Average-AUC:\", np.mean(AUC), np.std(AUC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986253b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
