{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ded897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Best auc: 0.5660372257082086\n",
      "Best ap: 0.5584837794303894\n",
      "Epoch: 1\n",
      "Best auc: 0.5660434353197172\n",
      "Best ap: 0.5585293173789978\n",
      "Average-percision: 0.5584804 2.7257745e-05\n",
      "Average-AUC: 0.5660373740955642 4.53037972982525e-06\n"
     ]
    }
   ],
   "source": [
    "#!usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import random\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from sklearn.cluster import KMeans\n",
    "from OpenAttMultiGL.model.MvAGC.metrics import clustering_metrics\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from time import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.simplefilter('error',ComplexWarning)\n",
    "from OpenAttMultiGL.utils.dataset import dataset\n",
    "from OpenAttMultiGL.utils.process import * \n",
    "from OpenAttMultiGL.model.MvAGC.embedder_link import evaluate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FGC_cora_modified(X, av, gnd, a, k, ind):\n",
    "        # Store some variables\n",
    "    gama=-1\n",
    "    nada = [1, 1]\n",
    "    X_hat_list=[]\n",
    "    X_hat_anchor_list=[]\n",
    "    A_hat_list=[]\n",
    "    final = []\n",
    "    for i in range(2):\n",
    "        A=av[i]\n",
    "        N = X.shape[0]\n",
    "        # print(\"N = {}\".format(N))\n",
    "        Im = np.eye(len(ind))\n",
    "        In = np.eye(N)\n",
    "        if sp.issparse(X):\n",
    "            X = X.todense()\n",
    "\n",
    "        # Normalize A\n",
    "        A = A + In\n",
    "        D = np.sum(A, axis=1)\n",
    "        D = np.power(D, -0.5)\n",
    "        D[np.isinf(D)] = 0\n",
    "        D = np.diagflat(D)\n",
    "        A = D.dot(A).dot(D)\n",
    "\n",
    "        # Get filter G\n",
    "        Ls = In - A\n",
    "        G = In - 0.2 * Ls #0.5 #0.8\n",
    "        G_ = In\n",
    "        X_hat = X\n",
    "        for i in range(k):\n",
    "            # G_ = G_.dot(G)\n",
    "            X_hat = G.dot(X_hat)\n",
    "        X_hat_list.append(X_hat)\n",
    "        A_hat = A[ind]  # (m,n)\n",
    "        A_hat_list.append(A_hat)\n",
    "        X_hat_anchor_list.append(X_hat[ind])\n",
    "    begin_time = time()\n",
    "    # Set the order of filter\n",
    "    for t in range(20):\n",
    "        tmp1=0\n",
    "        tmp2=0\n",
    "        for i in range(2):\n",
    "            tmp1 =tmp1+nada[i]*(X_hat_anchor_list[i].dot(X_hat_anchor_list[i].T) + a * Im)\n",
    "        for i in range(2):\n",
    "            tmp2 = tmp2+nada[i]*(X_hat_anchor_list[i].dot(X_hat_list[i].T) + a * A_hat_list[i])\n",
    "        S = np.linalg.inv(tmp1).dot(tmp2)\n",
    "        #for i in range(2):\n",
    "            #nada[i] = (-((np.linalg.norm(X_hat_list[i].T - (X_hat_anchor_list[i].T).dot(S))) ** 2 + a * (np.linalg.norm(S - A_hat_list[i])) ** 2) / (gama)) ** (1 / (gama - 1))\n",
    "            #print(\"nada value\")\n",
    "            #print(nada[i])\n",
    "        # res=0\n",
    "        # for j in range(2):\n",
    "        #     res = res + nada[j] * ((np.linalg.norm(X_hat_list[i].T - (X_hat_anchor_list[i].T).dot(S))) ** 2 + a * (np.linalg.norm(S - A_hat_list[i])) ** 2) + (nada[j]) ** (gama)\n",
    "        # final.append(res)\n",
    "        # print(res)\n",
    "    # sio.savemat(\"a.mat\", {'res': final})\n",
    "    return S, begin_time\n",
    "\n",
    "\n",
    "def main(X, av, gnd, m, a, k, ind):\n",
    "\n",
    "    N = X.shape[0]\n",
    "    begin_time_filter = time()\n",
    "    types = len(np.unique(gnd))\n",
    "    S, begin_time = FGC_cora_modified(X, av, gnd, a, k, ind)\n",
    "    D = np.sum(S, axis=1)\n",
    "    D = np.power(D, -0.5)\n",
    "    D[np.isinf(D)] = 0\n",
    "    D[np.isnan(D)] = 0\n",
    "    D = np.diagflat(D)  # (m,m)\n",
    "\n",
    "    S_hat = D.dot(S)  # (m,n)\n",
    "\n",
    "    S_hat_tmp = S_hat.dot(S_hat.T)  # (m,m)\n",
    "    S_hat_tmp[np.isinf(S_hat_tmp)] = 0\n",
    "    S_hat_tmp[np.isnan(S_hat_tmp)] = 0\n",
    "    # sigma, E = scipy.linalg.eig(S_hat_tmp)\n",
    "    E, sigma, v = sp.linalg.svds(S_hat_tmp, k=types, which='LM')\n",
    "    sigma = sigma.T\n",
    "    sigma = np.power(sigma, -0.5)\n",
    "    sigma[np.isinf(sigma)] = 0\n",
    "    sigma[np.isnan(sigma)] = 0\n",
    "    sigma = np.diagflat(sigma)\n",
    "    C_hat = (sigma.dot(E.T)).dot(S_hat)\n",
    "    C_hat[np.isinf(C_hat)] = 0\n",
    "    C_hat[np.isnan(C_hat)] = 0\n",
    "    C_hat = C_hat.astype(float)\n",
    "    #print(\"print shape of C_hat: \", C_hat.shape)\n",
    "    #kmeans = KMeans(n_clusters=types, random_state=37).fit(C_hat.T)\n",
    "\n",
    "    #predict_labels = kmeans.predict(C_hat.T)\n",
    "\n",
    "    #cm = clustering_metrics(gnd, predict_labels)\n",
    "    ##ac, nm, f1,adj,sim = cm.evaluationClusterModelFromLabel(m,a,k)\n",
    "    #end_time = time()\n",
    "    #tot_time = end_time - begin_time\n",
    "    #tot_time_filter = end_time - begin_time_filter\n",
    "    return C_hat\n",
    "\n",
    "\n",
    "def lower_bound(p, rd):\n",
    "    l = 0\n",
    "    r = len(p) - 1\n",
    "    while(l < r):\n",
    "        # print(\"rd = {}, l = {}, r= {}\".format(rd, l, r))\n",
    "        mid = (l + r) // 2\n",
    "        if(p[mid] > rd):\n",
    "            r = mid\n",
    "        else:\n",
    "            l = mid + 1\n",
    "    # print(\"rd = {}, l = {}, r= {}\".format(rd, l, r))\n",
    "    return l\n",
    "\n",
    "\n",
    "def node_sampling(A, m, alpha):\n",
    "    D = np.sum(A[0], axis=1).flatten()+np.sum(A[1], axis=1).flatten()\n",
    "\n",
    "    if(len(np.shape(D)) > 1):\n",
    "        D = D.A[0]\n",
    "        print(1)\n",
    "\n",
    "    D = D**alpha\n",
    "    D=D/10000\n",
    "    #print(D)\n",
    "    tot = np.sum(D)\n",
    "    #print(tot)\n",
    "    p = D / tot\n",
    "    #print(p)\n",
    "    for i in range(len(p) - 1):\n",
    "        p[i + 1] = p[i + 1] + p[i]\n",
    "    #print(p)\n",
    "    ind = []\n",
    "    vis = [0] * len(D)\n",
    "    while(m):\n",
    "        while(1):\n",
    "            rd = np.random.rand()\n",
    "            pos = lower_bound(p, rd)\n",
    "            if(vis[pos] == 1):\n",
    "                continue\n",
    "            else:\n",
    "                vis[pos] = 1\n",
    "                ind.append(pos)\n",
    "                m = m - 1\n",
    "                break\n",
    "    return ind\n",
    "\n",
    "\n",
    "def func(X, A, gnd):\n",
    "    m_init_list = [60] #anchor numbers\n",
    "    a_list = [5,15] #second term\n",
    "    k_init_list = [2] #juanjijieshu\n",
    "    f_alpha_init_list = [4] #important node\n",
    "    k_list = []\n",
    "    aa_list = []\n",
    "    i_list = []\n",
    "    ac_list = []\n",
    "    nm_list = []\n",
    "    f1_list = []\n",
    "    adj_list=[]\n",
    "    tm_list = []\n",
    "    tm_list_filter = []\n",
    "    f_alpha_list = []\n",
    "\n",
    "    N = X.shape[0]\n",
    "    tot_test = 1\n",
    "    ac_max = 0.0\n",
    "    xia = 0\n",
    "    tot = 0\n",
    "\n",
    "    # print(node_sampling(A, 20))\n",
    "    for k in k_init_list:\n",
    "        for i in m_init_list:\n",
    "            # print(\"now k = {}, now m = {}\".format(k, i))\n",
    "            for alpha in f_alpha_init_list:\n",
    "                ind = node_sampling(A, i, alpha)\n",
    "                ac_mean = 0\n",
    "                nm_mean = 0\n",
    "                f1_mean = 0\n",
    "                adj_mean=0\n",
    "                tm_mean = 0\n",
    "                for a in a_list:\n",
    "                    # continue\n",
    "                    acc, nmm, f11,adj, tm, tm_filter,sim = main(\n",
    "                        X, A, gnd, i, a, k, ind)\n",
    "                    print(\"m = {},k = {}, f_alpha = {},a  ={}, ac = {}, nmi = {}, f1 = {},adj={}, tm = {}, tm_filter = {}\".format(\n",
    "                        i, k, alpha, a, acc, nmm, f11,adj, tm, tm_filter))\n",
    "                    if(ac_mean < acc):\n",
    "                        ac_mean = acc\n",
    "                        nm_mean = nmm\n",
    "                        f1_mean = f11\n",
    "                        adj_mean=adj\n",
    "                        tm_mean = tm\n",
    "                        tm_mean_filter = tm_filter\n",
    "                    i_list.append(i)\n",
    "                    k_list.append(k)\n",
    "                    aa_list.append(a)\n",
    "                    f_alpha_list.append(alpha)\n",
    "                    ac_list.append(ac_mean)\n",
    "                    nm_list.append(nm_mean)\n",
    "                    f1_list.append(f1_mean)\n",
    "                    adj_list.append(adj_mean)\n",
    "                    tm_list.append(tm_mean)\n",
    "                    tm_list_filter.append(tm_mean_filter)\n",
    "                print(\"m = {}, k ={},f_alpha = {}, ac_mean = {},nm_mean = {},f1_mean = {},adj_mean={},tm_mean = {},tm_mean_filter = {}\\n\".format(\n",
    "                    i, k, alpha, ac_mean, nm_mean, f1_mean,adj_mean, tm_mean, tm_mean_filter))\n",
    "\n",
    "                if(ac_mean > ac_max):\n",
    "                    xia = tot\n",
    "                    ac_max = ac_mean\n",
    "\n",
    "                tot += 1\n",
    "\n",
    "    for i in range(len(i_list)):\n",
    "        print(\"m = {},k = {},f_alpha = {}, ac_mean = {}, nm_mean = {}, f1_mean = {},adj_mean={},tm_mean = {},tm_mean_filter ={}\".format(\n",
    "            i_list[i], k_list[i], f_alpha_list[i], ac_list[i], nm_list[i], f1_list[i],adj_list[i], tm_list[i], tm_list_filter[i]))\n",
    "    print(\"the best result is \")\n",
    "    print(\"m = {},k = {},f_alpha = {}, ac_mean = {}, nm_mean = {}, f1_mean = {},adj_mean={},tm_mean = {},tm_mean_filter = {}\".format(\n",
    "        i_list[xia], k_list[xia], f_alpha_list[xia], ac_list[xia], nm_list[xia], f1_list[xia],adj_list[xia], tm_list[xia], tm_list_filter[xia]))\n",
    "    return i_list[xia], k_list[xia], f_alpha_list[xia], ac_list[xia], nm_list[xia], f1_list[xia],adj_list[xia], tm_list[xia], tm_list_filter[xia]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataname = 'acm'#'ACM3025'#'AMAZON3025'\n",
    "    s = dataset(dataname)\n",
    "    num_classes = s.gcn_labels.shape[1]\n",
    "    #print(\"numclass \",num_classes)\n",
    "    s.gcn_labels = s.gcn_labels.T\n",
    "    \n",
    "    s.gcn_labels = np.argmax(s.gcn_labels, axis=0)\n",
    "    #data = pkl.load(open('mGCN_Toolbox/data/HAN/AMAZON/amazon.pkl', \"rb\"))\n",
    "    #print(type(data[\"feature\"]))\n",
    "    #s.features = np.array(s.features)\n",
    "    #print(\"T:\",s.features.shape)\n",
    "    #print(type(s.features))\n",
    "    if dataname == \"amazon\":\n",
    "        data = pkl.load(open('OpenAttMultiGL/data/HAN/AMAZON/amazon.pkl', \"rb\"))\n",
    "        A = data[\"IVI\"]\n",
    "        B = data[\"IBI\"]\n",
    "        C = data[\"IOI\"]\n",
    "        av=[]\n",
    "        av.append(A)\n",
    "        av.append(B)\n",
    "        av.append(C)\n",
    "    elif dataname == \"acm\":\n",
    "        data = sio.loadmat('OpenAttMultiGL/data/HAN/ACM/acm.mat')\n",
    "        A = data['PAP']\n",
    "        B = data['PLP']\n",
    "        av=[]\n",
    "        av.append(A)\n",
    "        av.append(B)\n",
    "    elif dataname == \"dblp\":\n",
    "        data = pkl.load(open('OpenAttMultiGL/data/HAN/DBLP/dblp.pkl', \"rb\"))\n",
    "        A = data[\"PAP\"]\n",
    "        B = data[\"PPrefP\"]\n",
    "        C = data[\"PATAP\"]\n",
    "            \n",
    "           \n",
    "        av=[]\n",
    "        av.append(A)\n",
    "        av.append(B)\n",
    "        av.append(C)\n",
    "    elif dataname == \"imdb\":\n",
    "        data = pkl.load(open('OpenAttMultiGL/data/HAN/IMDB/imdb.pkl', \"rb\"))\n",
    "        A = data[\"MDM\"]\n",
    "        B = data[\"MAM\"]\n",
    "            \n",
    "        \n",
    "        av=[]\n",
    "        av.append(A)\n",
    "        av.append(B)\n",
    "    \n",
    "    m_init_list = [60]\n",
    "    a_list = [5,15] \n",
    "    k_init_list = [2] \n",
    "    f_alpha_init_list = [4] \n",
    "        \n",
    "    ind = node_sampling(av, m_init_list[0], f_alpha_init_list[0])\n",
    "    \n",
    "    embeds = main(s.features, av, s.gcn_labels, m_init_list[0], a_list[0], k_init_list[0], ind)\n",
    "    #print(\"type:\",type(embeds))\n",
    "    embeds = torch.tensor(embeds).float()\n",
    "    #print(\"type:\",type(embeds))\n",
    "    split_edges = mask_test_edges(s.features, s.edge_list[0],1)\n",
    "    \n",
    "    split_edges['train']['label'] = torch.cat(\n",
    "        (split_edges['train']['label_pos'], split_edges['train']['label_neg']))#.to(args.device)\n",
    "    split_edges['valid']['label'] = torch.cat(\n",
    "        (split_edges['valid']['label_pos'], split_edges['valid']['label_neg']))#.to(args.device)\n",
    "    split_edges['test']['label'] = torch.cat(\n",
    "        (split_edges['test']['label_pos'], split_edges['test']['label_neg']))#.to(args.device)\n",
    "    s_edge = split_edges\n",
    "    #split_edge = mask_test_edges(t.HAN_features, split_edges, 1, 0.1, 0.5)\n",
    "    AUC, ap, hits = evaluate(embeds,s_edge,num_classes)\n",
    "    print(\"Average-precision:\", np.mean(ap), np.std(ap))\n",
    "    print(\"Average-AUC:\", np.mean(AUC), np.std(AUC))\n",
    "    \n",
    "\n",
    "    \n",
    "    #split_edges = mask_test_edges(p, s.edge_matrix[0],1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
